{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# References\n",
       "* https://github.com/normandipalo/faceID_beta/blob/master/faceid_beta.ipynb"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# References\n",
    "* https://github.com/normandipalo/faceID_beta/blob/master/faceid_beta.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x 2 root root 64 Mar 16 21:48 ./\r\n",
      "drwxr-xr-x 3 root root 96 Mar 16 21:48 ../\r\n"
     ]
    }
   ],
   "source": [
    "!ls -laFh /data/blogs/keras-faceid-recognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "FaceID recreation using face embeddings and RGBD images.\n",
       "Made by [Norman Di Palo](https://medium.com/@normandipalo), March 2018.\n",
       "\n",
       "Let''s start by downloading the dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "FaceID recreation using face embeddings and RGBD images.\n",
    "Made by [Norman Di Palo](https://medium.com/@normandipalo), March 2018.\n",
    "\n",
    "Let''s start by downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list=[\"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(151751).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(153054).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(154211).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(160440).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(160931).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(161342).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(163349).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-16)(164248).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(141550).zip\", \\\n",
    "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(142154).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(142457).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-17)(143016).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(132824).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(133201).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(133846).zip\", \\\n",
    "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(134239).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(134757).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(140516).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(143345).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(144316).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(145150).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(145623).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(150303).zip\", \\\n",
    "          \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(150650).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(151337).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(151650).zip\"]\n",
    "val_list=[\"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(152717).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(153532).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(154129).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(154728).zip\", \"http://vap.aau.dk/wp-content/uploads/VAPRBGD/(2012-05-18)(155357).zip\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "for link in link_list:\n",
    "  r = requests.get(link, stream=True)\n",
    "  z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "  z.extractall(\"/data/blogs/keras-faceid-recognition/faceid_train\")\n",
    "for link in val_list:\n",
    "  r = requests.get(link, stream=True)\n",
    "  z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "  z.extractall(\"/data/blogs/keras-faceid-recognition/faceid_val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Input preprocessing\n",
       "Here we create some functions that will create the input couple for our model,\n",
       "both correct and wrong couples. I created functions to have both depth-only\n",
       "input and RGBD inputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# Input preprocessing\n",
    "Here we create some functions that will create the input couple for our model,\n",
    "both correct and wrong couples. I created functions to have both depth-only\n",
    "input and RGBD inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_couple(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder == \"datalab\":\n",
    "      folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "  #  print(folder)\n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    "#    plt.imshow(mat_small)\n",
    "#    plt.show()\n",
    "    \n",
    "    mat2=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat2[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat2 = np.asarray(mat2)\n",
    "    mat2_small=mat2[140:340,220:420]\n",
    "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
    "#    plt.imshow(mat2_small)\n",
    "#    plt.show()\n",
    "    return np.array([mat_small, mat2_small])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.12369669  0.12369669  0.12369669 ...  0.12369669  0.12369669\n",
      "    0.12369669]\n",
      "  [ 0.12369669  0.12369669  0.12369669 ...  0.12369669  0.12369669\n",
      "    0.12369669]\n",
      "  [ 0.12369669  0.12369669  0.12369669 ...  0.12369669  0.12369669\n",
      "    0.12369669]\n",
      "  ...\n",
      "  [-0.13796997 -0.13796997 -0.13796997 ... -0.11463664 -0.11463664\n",
      "   -0.11713663]\n",
      "  [-0.14046997 -0.14046997 -0.13796997 ... -0.11463664 -0.11713663\n",
      "   -0.11713663]\n",
      "  [-0.14213663 -0.14046997 -0.14213663 ... -0.11713663 -0.11880331\n",
      "   -0.11880331]]\n",
      "\n",
      " [[ 0.11525767  0.11525767  0.11525767 ...  0.11525767  0.11525767\n",
      "    0.11525767]\n",
      "  [ 0.11525767  0.11525767  0.11525767 ...  0.11525767  0.11525767\n",
      "    0.11525767]\n",
      "  [ 0.11525767  0.11525767  0.11525767 ...  0.11525767  0.11525767\n",
      "    0.11525767]\n",
      "  ...\n",
      "  [-0.15224233 -0.15224233 -0.15224233 ... -0.12307566 -0.12307566\n",
      "   -0.121409  ]\n",
      "  [-0.15224233 -0.15224233 -0.15224233 ... -0.12557566 -0.12557566\n",
      "   -0.12307566]\n",
      "  [-0.153909   -0.153909   -0.153909   ... -0.12724233 -0.12557566\n",
      "   -0.12557566]]]\n"
     ]
    }
   ],
   "source": [
    "print(create_couple(\"/data/blogs/keras-faceid-recognition/faceid_train/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_couple_rgbd(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder == \"datalab\":\n",
    "      folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "  #  print(folder)\n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue    \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    img = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img.thumbnail((640,480))\n",
    "    img = np.asarray(img)\n",
    "    img = img[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    "#    plt.imshow(mat_small)\n",
    "#    plt.show()\n",
    "#    plt.imshow(img)\n",
    "#    plt.show()\n",
    "    \n",
    "    \n",
    "    mat2=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue\n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat2[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat2 = np.asarray(mat2)\n",
    "    mat2_small=mat2[140:340,220:420]\n",
    "    img2 = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img2.thumbnail((640,480))\n",
    "    img2 = np.asarray(img2)\n",
    "    img2 = img2[160:360,240:440]\n",
    "\n",
    " #   plt.imshow(img2)\n",
    " #   plt.show()\n",
    "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
    " #   plt.imshow(mat2_small)\n",
    " #   plt.show()\n",
    "    \n",
    "    full1 = np.zeros((200,200,4))\n",
    "    full1[:,:,:3] = img[:,:,:3]\n",
    "    full1[:,:,3] = mat_small\n",
    "    \n",
    "    full2 = np.zeros((200,200,4))\n",
    "    full2[:,:,:3] = img2[:,:,:3]\n",
    "    full2[:,:,3] = mat2_small\n",
    "    return np.array([full1, full2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.77000000e+02,  1.61000000e+02,  1.34000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.77000000e+02,  1.61000000e+02,  1.32000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.77000000e+02,  1.63000000e+02,  1.31000000e+02,\n",
       "           1.26669824e-01],\n",
       "         ...,\n",
       "         [ 1.55000000e+02,  1.48000000e+02,  1.21000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.54000000e+02,  1.47000000e+02,  1.21000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.53000000e+02,  1.46000000e+02,  1.21000000e+02,\n",
       "           1.26669824e-01]],\n",
       "\n",
       "        [[ 1.77000000e+02,  1.61000000e+02,  1.32000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.77000000e+02,  1.60000000e+02,  1.32000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.77000000e+02,  1.60000000e+02,  1.29000000e+02,\n",
       "           1.26669824e-01],\n",
       "         ...,\n",
       "         [ 1.55000000e+02,  1.47000000e+02,  1.20000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.52000000e+02,  1.47000000e+02,  1.18000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.51000000e+02,  1.47000000e+02,  1.18000000e+02,\n",
       "           1.26669824e-01]],\n",
       "\n",
       "        [[ 1.75000000e+02,  1.62000000e+02,  1.25000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.77000000e+02,  1.60000000e+02,  1.26000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.78000000e+02,  1.60000000e+02,  1.27000000e+02,\n",
       "           1.26669824e-01],\n",
       "         ...,\n",
       "         [ 1.53000000e+02,  1.46000000e+02,  1.20000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.51000000e+02,  1.48000000e+02,  1.19000000e+02,\n",
       "           1.26669824e-01],\n",
       "         [ 1.52000000e+02,  1.48000000e+02,  1.17000000e+02,\n",
       "           1.26669824e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.33000000e+02,  1.24000000e+02,  1.60000000e+02,\n",
       "          -7.58301765e-02],\n",
       "         [ 1.43000000e+02,  1.24000000e+02,  1.61000000e+02,\n",
       "          -7.58301765e-02],\n",
       "         [ 1.54000000e+02,  1.40000000e+02,  1.64000000e+02,\n",
       "          -7.58301765e-02],\n",
       "         ...,\n",
       "         [ 1.49000000e+02,  1.50000000e+02,  1.90000000e+02,\n",
       "          -7.41635114e-02],\n",
       "         [ 1.45000000e+02,  1.49000000e+02,  1.92000000e+02,\n",
       "          -7.41635114e-02],\n",
       "         [ 1.39000000e+02,  1.49000000e+02,  1.93000000e+02,\n",
       "          -7.41635114e-02]],\n",
       "\n",
       "        [[ 1.38000000e+02,  1.25000000e+02,  1.63000000e+02,\n",
       "          -7.83301815e-02],\n",
       "         [ 1.45000000e+02,  1.24000000e+02,  1.61000000e+02,\n",
       "          -7.83301815e-02],\n",
       "         [ 1.54000000e+02,  1.38000000e+02,  1.63000000e+02,\n",
       "          -7.83301815e-02],\n",
       "         ...,\n",
       "         [ 1.47000000e+02,  1.50000000e+02,  1.89000000e+02,\n",
       "          -7.58301765e-02],\n",
       "         [ 1.44000000e+02,  1.50000000e+02,  1.91000000e+02,\n",
       "          -7.58301765e-02],\n",
       "         [ 1.42000000e+02,  1.48000000e+02,  1.93000000e+02,\n",
       "          -7.58301765e-02]],\n",
       "\n",
       "        [[ 1.34000000e+02,  1.22000000e+02,  1.62000000e+02,\n",
       "          -7.99968466e-02],\n",
       "         [ 1.41000000e+02,  1.25000000e+02,  1.62000000e+02,\n",
       "          -7.99968466e-02],\n",
       "         [ 1.56000000e+02,  1.43000000e+02,  1.68000000e+02,\n",
       "          -7.99968466e-02],\n",
       "         ...,\n",
       "         [ 1.44000000e+02,  1.43000000e+02,  1.89000000e+02,\n",
       "          -7.83301815e-02],\n",
       "         [ 1.44000000e+02,  1.48000000e+02,  1.90000000e+02,\n",
       "          -7.83301815e-02],\n",
       "         [ 1.45000000e+02,  1.48000000e+02,  1.92000000e+02,\n",
       "          -7.58301765e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.74000000e+02,  1.62000000e+02,  1.33000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.75000000e+02,  1.61000000e+02,  1.34000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.74000000e+02,  1.61000000e+02,  1.35000000e+02,\n",
       "           1.01387434e-01],\n",
       "         ...,\n",
       "         [ 1.50000000e+02,  1.45000000e+02,  1.25000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.53000000e+02,  1.45000000e+02,  1.27000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.55000000e+02,  1.44000000e+02,  1.25000000e+02,\n",
       "           1.01387434e-01]],\n",
       "\n",
       "        [[ 1.75000000e+02,  1.61000000e+02,  1.33000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.75000000e+02,  1.61000000e+02,  1.35000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.74000000e+02,  1.61000000e+02,  1.35000000e+02,\n",
       "           1.01387434e-01],\n",
       "         ...,\n",
       "         [ 1.51000000e+02,  1.46000000e+02,  1.24000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.53000000e+02,  1.46000000e+02,  1.25000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.53000000e+02,  1.46000000e+02,  1.25000000e+02,\n",
       "           1.01387434e-01]],\n",
       "\n",
       "        [[ 1.76000000e+02,  1.62000000e+02,  1.33000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.76000000e+02,  1.61000000e+02,  1.34000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.75000000e+02,  1.62000000e+02,  1.34000000e+02,\n",
       "           1.01387434e-01],\n",
       "         ...,\n",
       "         [ 1.54000000e+02,  1.46000000e+02,  1.21000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.53000000e+02,  1.47000000e+02,  1.21000000e+02,\n",
       "           1.01387434e-01],\n",
       "         [ 1.52000000e+02,  1.47000000e+02,  1.20000000e+02,\n",
       "           1.01387434e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.32000000e+02,  1.24000000e+02,  1.60000000e+02,\n",
       "          -8.77792388e-02],\n",
       "         [ 1.32000000e+02,  1.24000000e+02,  1.60000000e+02,\n",
       "          -8.52792338e-02],\n",
       "         [ 1.33000000e+02,  1.28000000e+02,  1.61000000e+02,\n",
       "          -8.36125687e-02],\n",
       "         ...,\n",
       "         [ 1.28000000e+02,  1.39000000e+02,  1.81000000e+02,\n",
       "          -8.52792338e-02],\n",
       "         [ 1.17000000e+02,  1.20000000e+02,  1.71000000e+02,\n",
       "          -8.52792338e-02],\n",
       "         [ 1.11000000e+02,  1.03000000e+02,  1.59000000e+02,\n",
       "          -8.77792388e-02]],\n",
       "\n",
       "        [[ 1.32000000e+02,  1.23000000e+02,  1.59000000e+02,\n",
       "          -8.77792388e-02],\n",
       "         [ 1.34000000e+02,  1.25000000e+02,  1.60000000e+02,\n",
       "          -8.77792388e-02],\n",
       "         [ 1.34000000e+02,  1.29000000e+02,  1.60000000e+02,\n",
       "          -8.77792388e-02],\n",
       "         ...,\n",
       "         [ 1.29000000e+02,  1.37000000e+02,  1.77000000e+02,\n",
       "          -8.77792388e-02],\n",
       "         [ 1.15000000e+02,  1.13000000e+02,  1.62000000e+02,\n",
       "          -8.77792388e-02],\n",
       "         [ 1.12000000e+02,  1.03000000e+02,  1.56000000e+02,\n",
       "          -9.02792364e-02]],\n",
       "\n",
       "        [[ 1.30000000e+02,  1.23000000e+02,  1.58000000e+02,\n",
       "          -9.02792364e-02],\n",
       "         [ 1.35000000e+02,  1.27000000e+02,  1.59000000e+02,\n",
       "          -8.77792388e-02],\n",
       "         [ 1.37000000e+02,  1.30000000e+02,  1.61000000e+02,\n",
       "          -8.77792388e-02],\n",
       "         ...,\n",
       "         [ 1.30000000e+02,  1.31000000e+02,  1.69000000e+02,\n",
       "          -9.02792364e-02],\n",
       "         [ 1.13000000e+02,  1.09000000e+02,  1.55000000e+02,\n",
       "          -9.02792364e-02],\n",
       "         [ 1.08000000e+02,  1.05000000e+02,  1.56000000e+02,\n",
       "          -9.19459015e-02]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_couple_rgbd(\"/data/blogs/keras-faceid-recognition/faceid_val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wrong(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder == \"datalab\":\n",
    "      folder=np.random.choice(glob.glob(file_path + \"*\"))    \n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    " #   plt.imshow(mat_small)\n",
    " #   plt.show()\n",
    "    \n",
    "    folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder==folder2 or folder2==\"datalab\": #it activates if it chose the same folder\n",
    "        folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    mat2=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder2 + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue\n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat2[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat2 = np.asarray(mat2)\n",
    "    mat2_small=mat2[140:340,220:420]\n",
    "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
    " #   plt.imshow(mat2_small)\n",
    " #   plt.show()\n",
    "  \n",
    "    \n",
    "    return np.array([mat_small, mat2_small])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.09052429,  0.09052429,  0.09052429, ...,  0.09052429,\n",
       "          0.09052429,  0.09052429],\n",
       "        [ 0.09052429,  0.09052429,  0.09052429, ...,  0.09052429,\n",
       "          0.09052429,  0.09052429],\n",
       "        [ 0.09052429,  0.09052429,  0.09052429, ...,  0.09052429,\n",
       "          0.09052429,  0.09052429],\n",
       "        ...,\n",
       "        [-0.11197571, -0.11197571, -0.11030904, ...,  0.09052429,\n",
       "          0.09052429,  0.09052429],\n",
       "        [-0.11197571, -0.11197571, -0.11197571, ...,  0.09052429,\n",
       "          0.09052429,  0.09052429],\n",
       "        [-0.1144757 , -0.1144757 , -0.11197571, ...,  0.09052429,\n",
       "          0.09052429,  0.09052429]],\n",
       "\n",
       "       [[ 0.07465963,  0.07465963,  0.07465963, ...,  0.07465963,\n",
       "          0.07465963,  0.07465963],\n",
       "        [ 0.07465963,  0.07465963,  0.07465963, ...,  0.07465963,\n",
       "          0.07465963,  0.07465963],\n",
       "        [ 0.07465963,  0.07465963,  0.07465963, ...,  0.07465963,\n",
       "          0.07465963,  0.07465963],\n",
       "        ...,\n",
       "        [ 0.07465963,  0.07465963,  0.07465963, ...,  0.07465963,\n",
       "          0.07465963,  0.07465963],\n",
       "        [ 0.07465963,  0.07465963,  0.07465963, ...,  0.07465963,\n",
       "          0.07465963,  0.07465963],\n",
       "        [ 0.07465963,  0.07465963,  0.07465963, ...,  0.07465963,\n",
       "          0.07465963,  0.07465963]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_wrong(\"/data/blogs/keras-faceid-recognition/faceid_train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wrong_rgbd(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder == \"datalab\":\n",
    "      folder=np.random.choice(glob.glob(file_path + \"*\"))    \n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue\n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    img = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img.thumbnail((640,480))\n",
    "    img = np.asarray(img)\n",
    "    img = img[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    "  #  plt.imshow(img)\n",
    "  #  plt.show()\n",
    "  #  plt.imshow(mat_small)\n",
    "  #  plt.show()\n",
    "    folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    while folder==folder2 or folder2==\"datalab\": #it activates if it chose the same folder\n",
    "        folder2=np.random.choice(glob.glob(file_path + \"*\"))\n",
    "    mat2=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = np.random.choice(glob.glob(folder2 + \"/*.dat\"))\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat2[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat2 = np.asarray(mat2)\n",
    "    mat2_small=mat2[140:340,220:420]\n",
    "    img2 = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img2.thumbnail((640,480))\n",
    "    img2 = np.asarray(img2)\n",
    "    img2 = img2[140:340,220:420]\n",
    "    mat2_small=(mat2_small-np.mean(mat2_small))/np.max(mat2_small)\n",
    " #   plt.imshow(img2)\n",
    " #   plt.show()\n",
    " #   plt.imshow(mat2_small)\n",
    " #   plt.show()\n",
    "    full1 = np.zeros((200,200,4))\n",
    "    full1[:,:,:3] = img[:,:,:3]\n",
    "    full1[:,:,3] = mat_small\n",
    "    \n",
    "    full2 = np.zeros((200,200,4))\n",
    "    full2[:,:,:3] = img2[:,:,:3]\n",
    "    full2[:,:,3] = mat2_small\n",
    "    return np.array([full1, full2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_wrong_rgbd(\"/data/blogs/keras-faceid-recognition/faceid_val/\")[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Network crafting\n",
       "Now we create the network. We first manually create the constrative loss,\n",
       "then we define the network architecture starting from the SqueezeNet architecture,\n",
       "and then using it as a siamese-network for embedding faces into a manifold.\n",
       "(the network for now is very big and could be heavily optimized,\n",
       "but I just wanted to show a proof-of-concept)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# Network crafting\n",
    "Now we create the network. We first manually create the constrative loss,\n",
    "then we define the network architecture starting from the SqueezeNet architecture,\n",
    "and then using it as a siamese-network for embedding faces into a manifold.\n",
    "(the network for now is very big and could be heavily optimized,\n",
    "but I just wanted to show a proof-of-concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Lambda, ELU, concatenate, GlobalAveragePooling2D, Input, BatchNormalization, SeparableConv2D, Subtract, concatenate\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(inputs):\n",
    "    assert len(inputs) == 2, \\\n",
    "        'Euclidean distance needs 2 inputs, %d given' % len(inputs)\n",
    "    u, v = inputs\n",
    "    return K.sqrt(K.sum((K.square(u - v)), axis=1, keepdims=True))\n",
    "        \n",
    "\n",
    "def contrastive_loss(y_true,y_pred):\n",
    "    margin=1.\n",
    "    return K.mean((1. - y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0.)))\n",
    "   # return K.mean( K.square(y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire(x, squeeze=16, expand=64):\n",
    "    x = Convolution2D(squeeze, (1,1), padding='valid')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    left = Convolution2D(expand, (1,1), padding='valid')(x)\n",
    "    left = Activation('relu')(left)\n",
    "    \n",
    "    right = Convolution2D(expand, (3,3), padding='same')(x)\n",
    "    right = Activation('relu')(right)\n",
    "    \n",
    "    x = concatenate([left, right], axis=3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 98, 98, 64)   6464        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 98, 98, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 98, 98, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 48, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 48, 16)   1040        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 48, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 48, 48, 16)   272         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 48, 48, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 48, 48, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 48, 48, 16)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48, 48, 32)   0           activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 48, 48, 16)   528         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 48, 48, 16)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 48, 48, 16)   272         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 48, 48, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 48, 48, 16)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 48, 48, 16)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 48, 48, 32)   0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 23, 23, 32)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 23, 23, 32)   1056        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 23, 23, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 23, 23, 32)   1056        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 23, 23, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 23, 23, 32)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 23, 23, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 23, 23, 64)   0           activation_9[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 23, 23, 32)   2080        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 23, 23, 32)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 23, 23, 32)   1056        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 23, 23, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 23, 23, 32)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 23, 23, 32)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 23, 23, 64)   0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 11, 11, 64)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 11, 11, 48)   3120        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 11, 11, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 11, 11, 48)   2352        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 11, 11, 48)   20784       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 11, 11, 48)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 11, 11, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 11, 11, 96)   0           activation_15[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 11, 11, 48)   4656        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 11, 11, 48)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 48)   2352        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 48)   20784       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 11, 11, 48)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 11, 11, 48)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 11, 11, 96)   0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 64)   6208        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 11, 11, 64)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 11, 11, 64)   4160        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 11, 11, 64)   36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 11, 11, 64)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 11, 11, 64)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 11, 11, 128)  0           activation_21[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 11, 11, 64)   8256        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 11, 11, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 11, 11, 64)   4160        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 11, 11, 64)   36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 11, 11, 64)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 11, 11, 64)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 11, 11, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 11, 11, 128)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 11, 11, 512)  66048       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 11, 11, 512)  0           conv2d_26[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 253,952\n",
      "Trainable params: 253,824\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_input=Input(shape=(200,200,4))\n",
    "\n",
    "x = Convolution2D(64, (5, 5), strides=(2, 2), padding='valid')(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = fire(x, squeeze=16, expand=16)\n",
    "\n",
    "x = fire(x, squeeze=16, expand=16)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "x = fire(x, squeeze=32, expand=32)\n",
    "\n",
    "x = fire(x, squeeze=32, expand=32)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "x = fire(x, squeeze=48, expand=48)\n",
    "\n",
    "x = fire(x, squeeze=48, expand=48)\n",
    "\n",
    "x = fire(x, squeeze=64, expand=64)\n",
    "\n",
    "x = fire(x, squeeze=64, expand=64)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Convolution2D(512, (1, 1), padding='same')(x)\n",
    "out = Activation('relu')(x)\n",
    "\n",
    "\n",
    "modelsqueeze= Model(img_input, out)\n",
    "\n",
    "modelsqueeze.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200, 200, 4)       0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 11, 11, 512)       253952    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               31719936  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 32,039,552\n",
      "Trainable params: 32,039,424\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 200, 200, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 200, 200, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 128)          32039552    input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,039,552\n",
      "Trainable params: 32,039,424\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "im_in = Input(shape=(200,200,4))\n",
    "#wrong = Input(shape=(200,200,3))\n",
    "\n",
    "x1 = modelsqueeze(im_in)\n",
    "#x = Convolution2D(64, (5, 5), padding='valid', strides =(2,2))(x)\n",
    "\n",
    "#x1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x1)\n",
    "\n",
    "\"\"\"\n",
    "x1 = Convolution2D(256, (3,3), padding='valid', activation=\"relu\")(x1)\n",
    "x1 = Dropout(0.4)(x1)\n",
    "\n",
    "x1 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1))(x1)\n",
    "\n",
    "x1 = Convolution2D(256, (3,3), padding='valid', activation=\"relu\")(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.4)(x1)\n",
    "\n",
    "x1 = Convolution2D(64, (1,1), padding='same', activation=\"relu\")(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.4)(x1)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "x1 = Dense(512, activation=\"relu\")(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "#x1 = BatchNormalization()(x1)\n",
    "feat_x = Dense(128, activation=\"linear\")(x1)\n",
    "feat_x = Lambda(lambda  x: K.l2_normalize(x,axis=1))(feat_x)\n",
    "\n",
    "\n",
    "model_top = Model(inputs = [im_in], outputs = feat_x)\n",
    "\n",
    "model_top.summary()\n",
    "\n",
    "im_in1 = Input(shape=(200,200,4))\n",
    "im_in2 = Input(shape=(200,200,4))\n",
    "\n",
    "feat_x1 = model_top(im_in1)\n",
    "feat_x2 = model_top(im_in2)\n",
    "\n",
    "\n",
    "lambda_merge = Lambda(euclidean_distance)([feat_x1, feat_x2])\n",
    "\n",
    "\n",
    "model_final = Model(inputs = [im_in1, im_in2], outputs = lambda_merge)\n",
    "\n",
    "model_final.summary()\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "\n",
    "sgd = SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "model_final.compile(optimizer=adam, loss=contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Learning phase\n",
       "We write the generators that will give our model batches of data to train on, then we run the training."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# Learning phase\n",
    "We write the generators that will give our model batches of data to train on, then we run the training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(batch_size):\n",
    "  \n",
    "  while 1:\n",
    "    X=[]\n",
    "    y=[]\n",
    "    switch=True\n",
    "    for _ in range(batch_size):\n",
    "   #   switch += 1\n",
    "      if switch:\n",
    "     #   print(\"correct\")\n",
    "        X.append(create_couple_rgbd(\"/data/blogs/keras-faceid-recognition/faceid_train/\").reshape((2,200,200,4)))\n",
    "        y.append(np.array([0.]))\n",
    "      else:\n",
    "     #   print(\"wrong\")\n",
    "        X.append(create_wrong_rgbd(\"/data/blogs/keras-faceid-recognition/faceid_train/\").reshape((2,200,200,4)))\n",
    "        y.append(np.array([1.]))\n",
    "      switch=not switch\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    XX1=X[0,:]\n",
    "    XX2=X[1,:]\n",
    "    yield [X[:,0],X[:,1]],y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_generator(batch_size):\n",
    "  \n",
    "  while 1:\n",
    "    X=[]\n",
    "    y=[]\n",
    "    switch=True\n",
    "    for _ in range(batch_size):\n",
    "      if switch:\n",
    "        X.append(create_couple_rgbd(\"/data/blogs/keras-faceid-recognition/faceid_val/\").reshape((2,200,200,4)))\n",
    "        y.append(np.array([0.]))\n",
    "      else:\n",
    "        X.append(create_wrong_rgbd(\"/data/blogs/keras-faceid-recognition/faceid_val/\").reshape((2,200,200,4)))\n",
    "        y.append(np.array([1.]))\n",
    "      switch=not switch\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    XX1=X[0,:]\n",
    "    XX2=X[1,:]\n",
    "    yield [X[:,0],X[:,1]],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator(16)\n",
    "val_gen = val_generator(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 707s 24s/step - loss: 0.2580 - val_loss: 0.4847\n",
      "Epoch 2/50\n",
      "29/30 [============================>.] - ETA: 13s - loss: 0.2490"
     ]
    }
   ],
   "source": [
    "outputs = model_final.fit_generator(gen, steps_per_epoch=30, epochs=50, validation_data = val_gen, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "# Some model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cop = create_couple(\"/data/blogs/keras-faceid-recognition/faceid_val/\")\n",
    "model_final.evaluate([cop[0].reshape((1,200,200,1)), cop[1].reshape((1,200,200,1))], np.array([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cop = create_wrong_rgbd(\"/data/blogs/keras-faceid-recognition/faceid_val/\")\n",
    "model_final.predict([cop[0].reshape((1,200,200,4)), cop[1].reshape((1,200,200,4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "# Saving and loading the model\n",
    "The next cells show both how to save the model weights\n",
    "and upload them into your Drive, and then how to retrieve\n",
    "those weights from the Drive to load a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save(\"/data/blogs/keras-faceid-recognition/faceid_big_rgbd_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "# Raw output\n",
    "Here we create a model that outputs the embedding of an input face\n",
    "instead of the distance between two embeddings, so we can map those outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_in1 = Input(shape=(200,200,4))\n",
    "#im_in2 = Input(shape=(200,200,4))\n",
    "\n",
    "feat_x1 = model_top(im_in1)\n",
    "#feat_x2 = model_top(im_in2)\n",
    "\n",
    "\n",
    "\n",
    "model_output = Model(inputs = im_in1, outputs = feat_x1)\n",
    "\n",
    "model_output.summary()\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "\n",
    "sgd = SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "model_output.compile(optimizer=adam, loss=contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cop = create_couple_rgbd(\"/data/blogs/keras-faceid-recognition/faceid_val/\")\n",
    "model_output.predict(cop[0].reshape((1,200,200,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_rgbd(file_path):\n",
    "  #  print(folder)\n",
    "    mat=np.zeros((480,640), dtype='float32')\n",
    "    i=0\n",
    "    j=0\n",
    "    depth_file = file_path\n",
    "    with open(depth_file) as file:\n",
    "        for line in file:\n",
    "            vals = line.split('\\t')\n",
    "            for val in vals:\n",
    "                if val == \"\\n\": continue    \n",
    "                if int(val) > 1200 or int(val) == -1: val= 1200\n",
    "                mat[i][j]=float(int(val))\n",
    "                j+=1\n",
    "                j=j%640\n",
    "\n",
    "            i+=1\n",
    "        mat = np.asarray(mat)\n",
    "    mat_small=mat[140:340,220:420]\n",
    "    img = Image.open(depth_file[:-5] + \"c.bmp\")\n",
    "    img.thumbnail((640,480))\n",
    "    img = np.asarray(img)\n",
    "    img = img[140:340,220:420]\n",
    "    mat_small=(mat_small-np.mean(mat_small))/np.max(mat_small)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(True)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(mat_small)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(True)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    full1 = np.zeros((200,200,4))\n",
    "    full1[:,:,:3] = img[:,:,:3]\n",
    "    full1[:,:,3] = mat_small\n",
    "    \n",
    "    return np.array([full1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "# Data visualization\n",
    "Here we store the embeddings for all the faces in the dataset.\n",
    "Then, using both t-SNE and PCA, we visualize the embeddings going from 128 to 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=[]\n",
    "n=0\n",
    "for folder in glob.glob('/data/blogs/keras-faceid-recognition/faceid_train/*'):\n",
    "  i=0\n",
    "  for file in glob.glob(folder + '/*.dat'):\n",
    "    i+=1\n",
    "    outputs.append(model_output.predict(create_input_rgbd(file).reshape((1,200,200,4))))\n",
    "  print(i)\n",
    "  n+=1\n",
    "  print(\"Folder \", n, \" of \", len(glob.glob('/data/blogs/keras-faceid-recognition/faceid_train/*')))\n",
    "print(len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.asarray(outputs)\n",
    "outputs = outputs.reshape((-1,128))\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(2).fit_transform(outputs)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_PCA = PCA(3).fit_transform(outputs)\n",
    "print(X_PCA.shape)\n",
    "\n",
    "#X_embedded = TSNE(2).fit_transform(X_PCA)\n",
    "#print(X_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 0\n",
    "for i in range(len((X_embedded))):\n",
    "  el = X_embedded[i]\n",
    "  if i % 51 == 0 and not i==0:\n",
    "    color+=1\n",
    "    color=color%10\n",
    "  plt.scatter(el[0], el[1], color=\"C\" + str(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "# Distance between two arbitrary RGBD pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = ('/data/blogs/keras-faceid-recognition/faceid_train/(2012-05-16)(154211)/015_1_d.dat')\n",
    "inp1 = create_input_rgbd(file1)\n",
    "file1 = ('/data/blogs/keras-faceid-recognition/faceid_train/(2012-05-16)(154211)/011_1_d.dat')\n",
    "inp2 = create_input_rgbd(file1)\n",
    "\n",
    "model_final.predict([inp1, inp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
