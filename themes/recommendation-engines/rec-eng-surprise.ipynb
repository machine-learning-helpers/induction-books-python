{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# References\n",
       "* [Exploring Recommendation Systems](http://blog.fastforwardlabs.com/2018/01/22/exploring-recommendation-systems.html), by Shioulin, 22 January 2018\n",
       "* [Surprise project on GitHub](https://github.com/NicolasHug/Surprise)\n",
       "* [Surprise Web site](http://surpriselib.com)\n",
       "* [Movie-Lens data set](http://surprise.readthedocs.io/en/stable/dataset.html#dataset)\n",
       "                        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# References\n",
    "* [Exploring Recommendation Systems](http://blog.fastforwardlabs.com/2018/01/22/exploring-recommendation-systems.html), by Shioulin, 22 January 2018\n",
    "* [Surprise project on GitHub](https://github.com/NicolasHug/Surprise)\n",
    "* [Surprise Web site](http://surpriselib.com)\n",
    "* [Movie-Lens data set](http://surprise.readthedocs.io/en/stable/dataset.html#dataset)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Movie-Lens Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# Movie-Lens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9417547514595387"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9384  0.9332  0.9377  0.9333  0.9351  0.9355  0.0022  \n",
      "MAE (testset)     0.7405  0.7348  0.7377  0.7389  0.7351  0.7374  0.0022  \n",
      "Fit time          4.84    4.71    4.62    4.65    4.60    4.68    0.08    \n",
      "Test time         0.25    0.41    0.18    0.19    0.20    0.25    0.09    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (4.838788032531738,\n",
       "  4.7063822746276855,\n",
       "  4.621519565582275,\n",
       "  4.647674798965454,\n",
       "  4.60384464263916),\n",
       " 'test_mae': array([0.74048213, 0.73483854, 0.73766246, 0.73892974, 0.73514339]),\n",
       " 'test_rmse': array([0.93840196, 0.93319571, 0.93765372, 0.93332851, 0.93513885]),\n",
       " 'test_time': (0.25264811515808105,\n",
       "  0.4097118377685547,\n",
       "  0.17980575561523438,\n",
       "  0.1945943832397461,\n",
       "  0.1971583366394043)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8521315869223091\n",
      "{'reg_all': 0.4, 'lr_all': 0.002, 'n_epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "# Grid search parameters\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Custom Datasets"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "# Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.0006020069122314453, 9.202957153320312e-05),\n",
       " 'test_mae': array([1.04467587, 1.8052166 ]),\n",
       " 'test_rmse': array([1.29904915, 1.83048978]),\n",
       " 'test_time': (0.00040435791015625, 6.103515625e-05)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of the dataframe. Column names are irrelevant.\n",
    "ratings_dict = {'itemID': [1, 1, 1, 2, 2],\n",
    "                'userID': [9, 32, 2, 45, 'user_foo'],\n",
    "                'rating': [3, 2, 4, 3, 1]}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "cross_validate(NormalPredictor(), data, cv=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
